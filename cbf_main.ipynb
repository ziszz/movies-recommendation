{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zis\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from absl import logging\n",
    "from modules import components, pipeline\n",
    "from modules.utils import merge_dataset\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Merge dataset success'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_dataset(\"data/movies/movies.csv\", \"data/ratings/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"cbf_pipeline\"\n",
    "\n",
    "# pipeline inputs\n",
    "DATA_ROOT = \"data/merge\"\n",
    "TRANSFORM_MODULE_FILE = \"modules/cbf_transform.py\"\n",
    "TUNER_MODULE_FILE = \"modules/cbf_tuner.py\"\n",
    "TRAINER_MODULE_FILE = \"modules/cbf_trainer.py\"\n",
    "\n",
    "# pipeline outputs\n",
    "OUTPUT_BASE = \"outputs\"\n",
    "\n",
    "serving_model_dir = os.path.join(OUTPUT_BASE, \"serving_model\")\n",
    "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
    "metadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\cbf_pipeline\\Transform\\transform_graph\\19\\.temp_path\\tftransform_tmp\\e37ce6e7fd364bc38133514a529dab7d\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\cbf_pipeline\\Transform\\transform_graph\\19\\.temp_path\\tftransform_tmp\\e37ce6e7fd364bc38133514a529dab7d\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\cbf_pipeline\\Transform\\transform_graph\\19\\.temp_path\\tftransform_tmp\\d2bb7a64772244dbbd1fc28769a0313b\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\cbf_pipeline\\Transform\\transform_graph\\19\\.temp_path\\tftransform_tmp\\d2bb7a64772244dbbd1fc28769a0313b\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "ERROR:absl:Execution 21 failed.\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax [while running 'Run[Tuner]'] (cbf_tuner.py, line 79)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\common.py\"\u001b[0m, line \u001b[0;32m1417\u001b[0m, in \u001b[0;35mapache_beam.runners.common.DoFnRunner.process\u001b[0m\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\common.py\"\u001b[0m, line \u001b[0;32m837\u001b[0m, in \u001b[0;35mapache_beam.runners.common.PerWindowInvoker.invoke_process\u001b[0m\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\common.py\"\u001b[0m, line \u001b[0;32m983\u001b[0m, in \u001b[0;35mapache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\u001b[0m\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\beam\\beam_dag_runner.py\"\u001b[0m, line \u001b[0;32m90\u001b[0m, in \u001b[0;35mprocess\u001b[0m\n    self._run_node()\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\beam\\beam_dag_runner.py\"\u001b[0m, line \u001b[0;32m99\u001b[0m, in \u001b[0;35m_run_node\u001b[0m\n    launcher.Launcher(\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\portable\\launcher.py\"\u001b[0m, line \u001b[0;32m573\u001b[0m, in \u001b[0;35mlaunch\u001b[0m\n    executor_output = self._run_executor(execution_info)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\portable\\launcher.py\"\u001b[0m, line \u001b[0;32m448\u001b[0m, in \u001b[0;35m_run_executor\u001b[0m\n    executor_output = self._executor_operator.run_executor(execution_info)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\portable\\python_executor_operator.py\"\u001b[0m, line \u001b[0;32m135\u001b[0m, in \u001b[0;35mrun_executor\u001b[0m\n    return run_with_executor(execution_info, executor)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\portable\\python_executor_operator.py\"\u001b[0m, line \u001b[0;32m58\u001b[0m, in \u001b[0;35mrun_with_executor\u001b[0m\n    result = executor.Do(execution_info.input_dict, output_dict,\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\components\\tuner\\executor.py\"\u001b[0m, line \u001b[0;32m122\u001b[0m, in \u001b[0;35mDo\u001b[0m\n    tuner = search(input_dict, exec_properties, self._get_tmp_dir())\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\components\\tuner\\executor.py\"\u001b[0m, line \u001b[0;32m95\u001b[0m, in \u001b[0;35msearch\u001b[0m\n    tuner_fn = _get_tuner_fn(exec_properties)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\components\\tuner\\executor.py\"\u001b[0m, line \u001b[0;32m42\u001b[0m, in \u001b[0;35m_get_tuner_fn\u001b[0m\n    return udf_utils.get_fn(exec_properties, 'tuner_fn')\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\components\\util\\udf_utils.py\"\u001b[0m, line \u001b[0;32m56\u001b[0m, in \u001b[0;35mget_fn\u001b[0m\n    return import_utils.import_func_from_module(module_path, fn_name)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\utils\\import_utils.py\"\u001b[0m, line \u001b[0;32m60\u001b[0m, in \u001b[0;35mimport_func_from_module\u001b[0m\n    user_module = importlib.import_module(module_path)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\importlib\\__init__.py\"\u001b[0m, line \u001b[0;32m127\u001b[0m, in \u001b[0;35mimport_module\u001b[0m\n    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[0;32m1030\u001b[0m, in \u001b[0;35m_gcd_import\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[0;32m1007\u001b[0m, in \u001b[0;35m_find_and_load\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[0;32m986\u001b[0m, in \u001b[0;35m_find_and_load_unlocked\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[0;32m680\u001b[0m, in \u001b[0;35m_load_unlocked\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[0;32m846\u001b[0m, in \u001b[0;35mexec_module\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[0;32m983\u001b[0m, in \u001b[0;35mget_code\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[0;32m913\u001b[0m, in \u001b[0;35msource_to_code\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[1;36m, line \u001b[1;32m228\u001b[1;36m, in \u001b[1;35m_call_with_frames_removed\u001b[1;36m\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\zis\\AppData\\Local\\Temp\\tmp82qmuzbd\\cbf_tuner.py\"\u001b[1;36m, line \u001b[1;32m79\u001b[0m\n\u001b[1;33m    inputs=[user_input, i for i in movie_features], outputs=outputs)\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3457\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"C:\\Users\\zis\\AppData\\Local\\Temp\\ipykernel_18876\\1785530796.py\"\u001b[0m, line \u001b[0;32m20\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    BeamDagRunner().run(pipeline)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\portable\\tfx_runner.py\"\u001b[0m, line \u001b[0;32m124\u001b[0m, in \u001b[0;35mrun\u001b[0m\n    return self.run_with_ir(pipeline_pb, run_options=run_options_pb, **kwargs)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\beam\\beam_dag_runner.py\"\u001b[0m, line \u001b[0;32m297\u001b[0m, in \u001b[0;35mrun_with_ir\u001b[0m\n    logging.info('Node %s is scheduled.', node_id)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\pipeline.py\"\u001b[0m, line \u001b[0;32m597\u001b[0m, in \u001b[0;35m__exit__\u001b[0m\n    self.result = self.run()\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\pipeline.py\"\u001b[0m, line \u001b[0;32m574\u001b[0m, in \u001b[0;35mrun\u001b[0m\n    return self.runner.run_pipeline(self, self._options)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\runners\\direct\\direct_runner.py\"\u001b[0m, line \u001b[0;32m131\u001b[0m, in \u001b[0;35mrun_pipeline\u001b[0m\n    return runner.run_pipeline(pipeline, options)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\fn_runner.py\"\u001b[0m, line \u001b[0;32m199\u001b[0m, in \u001b[0;35mrun_pipeline\u001b[0m\n    self._latest_run_result = self.run_via_runner_api(\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\fn_runner.py\"\u001b[0m, line \u001b[0;32m212\u001b[0m, in \u001b[0;35mrun_via_runner_api\u001b[0m\n    return self.run_stages(stage_context, stages)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\fn_runner.py\"\u001b[0m, line \u001b[0;32m442\u001b[0m, in \u001b[0;35mrun_stages\u001b[0m\n    bundle_results = self._execute_bundle(\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\fn_runner.py\"\u001b[0m, line \u001b[0;32m770\u001b[0m, in \u001b[0;35m_execute_bundle\u001b[0m\n    self._run_bundle(\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\fn_runner.py\"\u001b[0m, line \u001b[0;32m999\u001b[0m, in \u001b[0;35m_run_bundle\u001b[0m\n    result, splits = bundle_manager.process_bundle(\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\fn_runner.py\"\u001b[0m, line \u001b[0;32m1309\u001b[0m, in \u001b[0;35mprocess_bundle\u001b[0m\n    result_future = self._worker_handler.control_conn.push(process_bundle_req)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\worker_handlers.py\"\u001b[0m, line \u001b[0;32m379\u001b[0m, in \u001b[0;35mpush\u001b[0m\n    response = self.worker.do_instruction(request)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\runners\\worker\\sdk_worker.py\"\u001b[0m, line \u001b[0;32m596\u001b[0m, in \u001b[0;35mdo_instruction\u001b[0m\n    return getattr(self, request_type)(\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\runners\\worker\\sdk_worker.py\"\u001b[0m, line \u001b[0;32m634\u001b[0m, in \u001b[0;35mprocess_bundle\u001b[0m\n    bundle_processor.process_bundle(instruction_id))\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\runners\\worker\\bundle_processor.py\"\u001b[0m, line \u001b[0;32m1003\u001b[0m, in \u001b[0;35mprocess_bundle\u001b[0m\n    input_op_by_transform_id[element.transform_id].process_encoded(\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\apache_beam\\runners\\worker\\bundle_processor.py\"\u001b[0m, line \u001b[0;32m227\u001b[0m, in \u001b[0;35mprocess_encoded\u001b[0m\n    self.output(decoded_value)\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\worker\\operations.py\"\u001b[0m, line \u001b[0;32m526\u001b[0m, in \u001b[0;35mapache_beam.runners.worker.operations.Operation.output\u001b[0m\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\worker\\operations.py\"\u001b[0m, line \u001b[0;32m528\u001b[0m, in \u001b[0;35mapache_beam.runners.worker.operations.Operation.output\u001b[0m\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\worker\\operations.py\"\u001b[0m, line \u001b[0;32m237\u001b[0m, in \u001b[0;35mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0m\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\worker\\operations.py\"\u001b[0m, line \u001b[0;32m240\u001b[0m, in \u001b[0;35mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[0m\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\worker\\operations.py\"\u001b[0m, line \u001b[0;32m907\u001b[0m, in \u001b[0;35mapache_beam.runners.worker.operations.DoOperation.process\u001b[0m\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\worker\\operations.py\"\u001b[0m, line \u001b[0;32m908\u001b[0m, in \u001b[0;35mapache_beam.runners.worker.operations.DoOperation.process\u001b[0m\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\common.py\"\u001b[0m, line \u001b[0;32m1419\u001b[0m, in \u001b[0;35mapache_beam.runners.common.DoFnRunner.process\u001b[0m\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\common.py\"\u001b[0m, line \u001b[0;32m1507\u001b[0m, in \u001b[0;35mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[0m\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\common.py\"\u001b[0m, line \u001b[0;32m1417\u001b[0m, in \u001b[0;35mapache_beam.runners.common.DoFnRunner.process\u001b[0m\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\common.py\"\u001b[0m, line \u001b[0;32m837\u001b[0m, in \u001b[0;35mapache_beam.runners.common.PerWindowInvoker.invoke_process\u001b[0m\n",
      "  File \u001b[0;32m\"apache_beam\\runners\\common.py\"\u001b[0m, line \u001b[0;32m983\u001b[0m, in \u001b[0;35mapache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\u001b[0m\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\beam\\beam_dag_runner.py\"\u001b[0m, line \u001b[0;32m90\u001b[0m, in \u001b[0;35mprocess\u001b[0m\n    self._run_node()\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\beam\\beam_dag_runner.py\"\u001b[0m, line \u001b[0;32m99\u001b[0m, in \u001b[0;35m_run_node\u001b[0m\n    launcher.Launcher(\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\portable\\launcher.py\"\u001b[0m, line \u001b[0;32m573\u001b[0m, in \u001b[0;35mlaunch\u001b[0m\n    executor_output = self._run_executor(execution_info)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\portable\\launcher.py\"\u001b[0m, line \u001b[0;32m448\u001b[0m, in \u001b[0;35m_run_executor\u001b[0m\n    executor_output = self._executor_operator.run_executor(execution_info)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\portable\\python_executor_operator.py\"\u001b[0m, line \u001b[0;32m135\u001b[0m, in \u001b[0;35mrun_executor\u001b[0m\n    return run_with_executor(execution_info, executor)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\orchestration\\portable\\python_executor_operator.py\"\u001b[0m, line \u001b[0;32m58\u001b[0m, in \u001b[0;35mrun_with_executor\u001b[0m\n    result = executor.Do(execution_info.input_dict, output_dict,\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\components\\tuner\\executor.py\"\u001b[0m, line \u001b[0;32m122\u001b[0m, in \u001b[0;35mDo\u001b[0m\n    tuner = search(input_dict, exec_properties, self._get_tmp_dir())\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\components\\tuner\\executor.py\"\u001b[0m, line \u001b[0;32m95\u001b[0m, in \u001b[0;35msearch\u001b[0m\n    tuner_fn = _get_tuner_fn(exec_properties)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\components\\tuner\\executor.py\"\u001b[0m, line \u001b[0;32m42\u001b[0m, in \u001b[0;35m_get_tuner_fn\u001b[0m\n    return udf_utils.get_fn(exec_properties, 'tuner_fn')\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\components\\util\\udf_utils.py\"\u001b[0m, line \u001b[0;32m56\u001b[0m, in \u001b[0;35mget_fn\u001b[0m\n    return import_utils.import_func_from_module(module_path, fn_name)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\site-packages\\tfx\\utils\\import_utils.py\"\u001b[0m, line \u001b[0;32m60\u001b[0m, in \u001b[0;35mimport_func_from_module\u001b[0m\n    user_module = importlib.import_module(module_path)\n",
      "  File \u001b[0;32m\"c:\\Users\\zis\\anaconda3\\lib\\importlib\\__init__.py\"\u001b[0m, line \u001b[0;32m127\u001b[0m, in \u001b[0;35mimport_module\u001b[0m\n    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[0;32m1030\u001b[0m, in \u001b[0;35m_gcd_import\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[0;32m1007\u001b[0m, in \u001b[0;35m_find_and_load\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[0;32m986\u001b[0m, in \u001b[0;35m_find_and_load_unlocked\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[0;32m680\u001b[0m, in \u001b[0;35m_load_unlocked\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[0;32m846\u001b[0m, in \u001b[0;35mexec_module\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[0;32m983\u001b[0m, in \u001b[0;35mget_code\u001b[0m\n",
      "  File \u001b[0;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[0;32m913\u001b[0m, in \u001b[0;35msource_to_code\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[1;36m, line \u001b[1;32m228\u001b[1;36m, in \u001b[1;35m_call_with_frames_removed\u001b[1;36m\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\zis\\AppData\\Local\\Temp\\tmp82qmuzbd\\cbf_tuner.py\"\u001b[1;36m, line \u001b[1;32m79\u001b[0m\n\u001b[1;33m    inputs=[user_input, i for i in movie_features], outputs=outputs)\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax [while running 'Run[Tuner]']\n"
     ]
    }
   ],
   "source": [
    "components = components.init_components(\n",
    "    data_dir=DATA_ROOT,\n",
    "    transform_module=TRANSFORM_MODULE_FILE,\n",
    "    tuner_module=TUNER_MODULE_FILE,\n",
    "    trainer_module=TRAINER_MODULE_FILE,\n",
    "    train_steps=1000,\n",
    "    eval_steps=500,\n",
    "    serving_model_dir=os.path.join(\n",
    "        serving_model_dir, \"cbf_model\"),\n",
    "    epochs=5,\n",
    ")\n",
    "\n",
    "pipeline = pipeline.init_pipeline(\n",
    "    pipeline_root=pipeline_root,\n",
    "    pipeline_name=PIPELINE_NAME,\n",
    "    metadata_path=metadata_path,\n",
    "    components=components,\n",
    ")\n",
    "\n",
    "BeamDagRunner().run(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b69c515608d8896b1c8a42bf0e6b15f6e8100a733568a2d96272b822b9ba8fd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
