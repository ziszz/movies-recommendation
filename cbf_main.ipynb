{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
                        "  \"class\": algorithms.Blowfish,\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import glob\n",
                "import pandas as pd\n",
                "import tensorflow as tf\n",
                "from absl import logging\n",
                "from modules import components, pipeline\n",
                "from modules.utils import merge_dataset\n",
                "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "PIPELINE_NAME = \"cbf_pipeline\"\n",
                "\n",
                "# pipeline inputs\n",
                "DATA_ROOT = \"data/merge\"\n",
                "TRANSFORM_MODULE_FILE = \"modules/cbf_transform.py\"\n",
                "TUNER_MODULE_FILE = \"modules/cbf_tuner.py\"\n",
                "TRAINER_MODULE_FILE = \"modules/cbf_trainer.py\"\n",
                "\n",
                "# pipeline outputs\n",
                "OUTPUT_BASE = \"outputs\"\n",
                "\n",
                "serving_model_dir = os.path.join(OUTPUT_BASE, \"serving_model\")\n",
                "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
                "metadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Trial 30 Complete [00h 03m 48s]\n",
                        "multi_objective: 11.411754369735718\n",
                        "\n",
                        "Best multi_objective So Far: 9.46040654182434\n",
                        "Total elapsed time: 01h 50m 11s\n",
                        "INFO:tensorflow:Oracle triggered exit\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Oracle triggered exit\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Results summary\n",
                        "Results in outputs\\cbf_pipeline\\Tuner\\.system\\executor_execution\\14\\.temp\\14\\kt_hyperband\n",
                        "Showing 10 best trials\n",
                        "<keras_tuner.engine.objective.MultiObjective object at 0x00000201BAF97D30>\n",
                        "Trial summary\n",
                        "Hyperparameters:\n",
                        "dense_unit1: 328\n",
                        "dense_unit2: 8\n",
                        "dense_unit3: 72\n",
                        "learning_rate: 0.01\n",
                        "tuner/epochs: 10\n",
                        "tuner/initial_epoch: 4\n",
                        "tuner/bracket: 2\n",
                        "tuner/round: 2\n",
                        "tuner/trial_id: 0012\n",
                        "Score: 9.46040654182434\n",
                        "Trial summary\n",
                        "Hyperparameters:\n",
                        "dense_unit1: 328\n",
                        "dense_unit2: 8\n",
                        "dense_unit3: 72\n",
                        "learning_rate: 0.01\n",
                        "tuner/epochs: 2\n",
                        "tuner/initial_epoch: 0\n",
                        "tuner/bracket: 2\n",
                        "tuner/round: 0\n",
                        "Score: 9.47113037109375\n",
                        "Trial summary\n",
                        "Hyperparameters:\n",
                        "dense_unit1: 328\n",
                        "dense_unit2: 8\n",
                        "dense_unit3: 72\n",
                        "learning_rate: 0.01\n",
                        "tuner/epochs: 4\n",
                        "tuner/initial_epoch: 2\n",
                        "tuner/bracket: 2\n",
                        "tuner/round: 1\n",
                        "tuner/trial_id: 0003\n",
                        "Score: 9.472593784332275\n",
                        "Trial summary\n",
                        "Hyperparameters:\n",
                        "dense_unit1: 360\n",
                        "dense_unit2: 424\n",
                        "dense_unit3: 136\n",
                        "learning_rate: 0.01\n",
                        "tuner/epochs: 4\n",
                        "tuner/initial_epoch: 0\n",
                        "tuner/bracket: 1\n",
                        "tuner/round: 0\n",
                        "Score: 9.476088047027588\n",
                        "Trial summary\n",
                        "Hyperparameters:\n",
                        "dense_unit1: 360\n",
                        "dense_unit2: 424\n",
                        "dense_unit3: 136\n",
                        "learning_rate: 0.01\n",
                        "tuner/epochs: 10\n",
                        "tuner/initial_epoch: 4\n",
                        "tuner/bracket: 1\n",
                        "tuner/round: 1\n",
                        "tuner/trial_id: 0019\n",
                        "Score: 9.479637861251831\n",
                        "Trial summary\n",
                        "Hyperparameters:\n",
                        "dense_unit1: 264\n",
                        "dense_unit2: 40\n",
                        "dense_unit3: 328\n",
                        "learning_rate: 0.001\n",
                        "tuner/epochs: 4\n",
                        "tuner/initial_epoch: 0\n",
                        "tuner/bracket: 1\n",
                        "tuner/round: 0\n",
                        "Score: 9.479930877685547\n",
                        "Trial summary\n",
                        "Hyperparameters:\n",
                        "dense_unit1: 264\n",
                        "dense_unit2: 40\n",
                        "dense_unit3: 328\n",
                        "learning_rate: 0.001\n",
                        "tuner/epochs: 10\n",
                        "tuner/initial_epoch: 4\n",
                        "tuner/bracket: 1\n",
                        "tuner/round: 1\n",
                        "tuner/trial_id: 0021\n",
                        "Score: 9.483018398284912\n",
                        "Trial summary\n",
                        "Hyperparameters:\n",
                        "dense_unit1: 200\n",
                        "dense_unit2: 136\n",
                        "dense_unit3: 328\n",
                        "learning_rate: 0.01\n",
                        "tuner/epochs: 10\n",
                        "tuner/initial_epoch: 4\n",
                        "tuner/bracket: 2\n",
                        "tuner/round: 2\n",
                        "tuner/trial_id: 0015\n",
                        "Score: 9.485212564468384\n",
                        "Trial summary\n",
                        "Hyperparameters:\n",
                        "dense_unit1: 200\n",
                        "dense_unit2: 136\n",
                        "dense_unit3: 328\n",
                        "learning_rate: 0.01\n",
                        "tuner/epochs: 4\n",
                        "tuner/initial_epoch: 2\n",
                        "tuner/bracket: 2\n",
                        "tuner/round: 1\n",
                        "tuner/trial_id: 0002\n",
                        "Score: 9.489144563674927\n",
                        "Trial summary\n",
                        "Hyperparameters:\n",
                        "dense_unit1: 232\n",
                        "dense_unit2: 200\n",
                        "dense_unit3: 360\n",
                        "learning_rate: 0.001\n",
                        "tuner/epochs: 2\n",
                        "tuner/initial_epoch: 0\n",
                        "tuner/bracket: 2\n",
                        "tuner/round: 0\n",
                        "Score: 9.494000911712646\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
                        "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
                        "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: \"model_1\"\n",
                        "__________________________________________________________________________________________________\n",
                        " Layer (type)                   Output Shape         Param #     Connected to                     \n",
                        "==================================================================================================\n",
                        " genres_xf (InputLayer)         [(None, 1)]          0           []                               \n",
                        "                                                                                                  \n",
                        " title_xf (InputLayer)          [(None, 1)]          0           []                               \n",
                        "                                                                                                  \n",
                        " userid_xf (InputLayer)         [(None, 1)]          0           []                               \n",
                        "                                                                                                  \n",
                        " concatenate_1 (Concatenate)    (None, 2)            0           ['genres_xf[0][0]',              \n",
                        "                                                                  'title_xf[0][0]']               \n",
                        "                                                                                                  \n",
                        " sequential_2 (Sequential)      (None, 72)           3936        ['userid_xf[0][0]']              \n",
                        "                                                                                                  \n",
                        " sequential_3 (Sequential)      (None, 72)           4264        ['concatenate_1[0][0]']          \n",
                        "                                                                                                  \n",
                        " tf.math.l2_normalize_2 (TFOpLa  (None, 72)          0           ['sequential_2[0][0]']           \n",
                        " mbda)                                                                                            \n",
                        "                                                                                                  \n",
                        " tf.math.l2_normalize_3 (TFOpLa  (None, 72)          0           ['sequential_3[0][0]']           \n",
                        " mbda)                                                                                            \n",
                        "                                                                                                  \n",
                        " dot_1 (Dot)                    (None, 1)            0           ['tf.math.l2_normalize_2[0][0]', \n",
                        "                                                                  'tf.math.l2_normalize_3[0][0]'] \n",
                        "                                                                                                  \n",
                        "==================================================================================================\n",
                        "Total params: 8,200\n",
                        "Trainable params: 8,200\n",
                        "Non-trainable params: 0\n",
                        "__________________________________________________________________________________________________\n",
                        "Epoch 1/10\n",
                        "1000/1000 [==============================] - 22s 21ms/step - loss: 7.0862 - root_mean_squared_error: 2.6620 - val_loss: 6.8607 - val_root_mean_squared_error: 2.6193\n",
                        "Epoch 2/10\n",
                        "1000/1000 [==============================] - 19s 19ms/step - loss: 6.6878 - root_mean_squared_error: 2.5861 - val_loss: 6.8580 - val_root_mean_squared_error: 2.6188\n",
                        "Epoch 3/10\n",
                        "1000/1000 [==============================] - 17s 17ms/step - loss: 7.0171 - root_mean_squared_error: 2.6490 - val_loss: 6.8474 - val_root_mean_squared_error: 2.6167\n",
                        "Epoch 4/10\n",
                        "1000/1000 [==============================] - 19s 19ms/step - loss: 6.7043 - root_mean_squared_error: 2.5893 - val_loss: 6.8502 - val_root_mean_squared_error: 2.6173\n",
                        "Epoch 5/10\n",
                        "1000/1000 [==============================] - 18s 18ms/step - loss: 7.0043 - root_mean_squared_error: 2.6466 - val_loss: 6.8532 - val_root_mean_squared_error: 2.6179\n",
                        "Epoch 6/10\n",
                        "1000/1000 [==============================] - 17s 17ms/step - loss: 6.7126 - root_mean_squared_error: 2.5909 - val_loss: 6.8540 - val_root_mean_squared_error: 2.6180\n",
                        "Epoch 7/10\n",
                        "1000/1000 [==============================] - 18s 18ms/step - loss: 6.9977 - root_mean_squared_error: 2.6453 - val_loss: 6.8515 - val_root_mean_squared_error: 2.6175\n",
                        "Epoch 8/10\n",
                        "1000/1000 [==============================] - 20s 20ms/step - loss: 6.7283 - root_mean_squared_error: 2.5939 - val_loss: 6.8496 - val_root_mean_squared_error: 2.6172\n",
                        "Epoch 9/10\n",
                        "1000/1000 [==============================] - 18s 18ms/step - loss: 6.9710 - root_mean_squared_error: 2.6403 - val_loss: 6.8492 - val_root_mean_squared_error: 2.6171\n",
                        "Epoch 10/10\n",
                        "1000/1000 [==============================] - 17s 17ms/step - loss: 6.7601 - root_mean_squared_error: 2.6000 - val_loss: 6.8523 - val_root_mean_squared_error: 2.6177\n",
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\cbf_pipeline\\Trainer\\model\\15\\Format-Serving\\assets\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\cbf_pipeline\\Trainer\\model\\15\\Format-Serving\\assets\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002013A525EE0> and <keras.engine.input_layer.InputLayer object at 0x0000020140C076A0>).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002013A525EE0> and <keras.engine.input_layer.InputLayer object at 0x0000020140C076A0>).\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000201B813FCD0> and <keras.engine.input_layer.InputLayer object at 0x0000020163A3A520>).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000201B813FCD0> and <keras.engine.input_layer.InputLayer object at 0x0000020163A3A520>).\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000020157C1D760> and <keras.engine.input_layer.InputLayer object at 0x0000020141102910>).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000020157C1D760> and <keras.engine.input_layer.InputLayer object at 0x0000020141102910>).\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000020161F46C70> and <keras.engine.input_layer.InputLayer object at 0x00000201B7EF5190>).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000020161F46C70> and <keras.engine.input_layer.InputLayer object at 0x00000201B7EF5190>).\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002015D04E430> and <keras.engine.input_layer.InputLayer object at 0x00000201B8011F10>).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002015D04E430> and <keras.engine.input_layer.InputLayer object at 0x00000201B8011F10>).\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000201E332E5E0> and <keras.engine.input_layer.InputLayer object at 0x00000201E331C0A0>).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000201E332E5E0> and <keras.engine.input_layer.InputLayer object at 0x00000201E331C0A0>).\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000201F30B4B50> and <keras.engine.input_layer.InputLayer object at 0x00000201F309D9D0>).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000201F30B4B50> and <keras.engine.input_layer.InputLayer object at 0x00000201F309D9D0>).\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000201F3530310> and <keras.engine.input_layer.InputLayer object at 0x00000201F34C7700>).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000201F3530310> and <keras.engine.input_layer.InputLayer object at 0x00000201F34C7700>).\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:From c:\\Users\\zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
                        "Instructions for updating:\n",
                        "Use eager execution and: \n",
                        "`tf.data.TFRecordDataset(path)`\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:From c:\\Users\\zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
                        "Instructions for updating:\n",
                        "Use eager execution and: \n",
                        "`tf.data.TFRecordDataset(path)`\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
                    ]
                }
            ],
            "source": [
                "components = components.init_components(\n",
                "    data_dir=DATA_ROOT,\n",
                "    transform_module=TRANSFORM_MODULE_FILE,\n",
                "    tuner_module=TUNER_MODULE_FILE,\n",
                "    trainer_module=TRAINER_MODULE_FILE,\n",
                "    train_steps=1000,\n",
                "    eval_steps=500,\n",
                "    serving_model_dir=os.path.join(\n",
                "        serving_model_dir, \"cbf_model\"),\n",
                "    epochs=10,\n",
                ")\n",
                "\n",
                "pipeline = pipeline.init_pipeline(\n",
                "    pipeline_root=pipeline_root,\n",
                "    pipeline_name=PIPELINE_NAME,\n",
                "    metadata_path=metadata_path,\n",
                "    components=components,\n",
                ")\n",
                "\n",
                "BeamDagRunner().run(pipeline)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "movies-rec",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.15"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "6e25223de69fee5703ad0c26aae235f0717de5f7833afcaf5995714c1d7d9212"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
