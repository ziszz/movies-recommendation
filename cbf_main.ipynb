{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from absl import logging\n",
    "from modules import components, pipeline\n",
    "from modules.utils import merge_dataset\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"cbf_pipeline\"\n",
    "\n",
    "# pipeline inputs\n",
    "DATA_ROOT = \"data/merge\"\n",
    "TRANSFORM_MODULE_FILE = \"modules/cbf_transform.py\"\n",
    "TUNER_MODULE_FILE = \"modules/cbf_tuner.py\"\n",
    "TRAINER_MODULE_FILE = \"modules/cbf_trainer.py\"\n",
    "\n",
    "# pipeline outputs\n",
    "OUTPUT_BASE = \"outputs\"\n",
    "\n",
    "serving_model_dir = os.path.join(OUTPUT_BASE, \"serving_model\")\n",
    "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
    "metadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 04s]\n",
      "multi_objective: 2.616243839263916\n",
      "\n",
      "Best multi_objective So Far: 2.615494728088379\n",
      "Total elapsed time: 00h 07m 12s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in outputs\\cbf_pipeline\\Tuner\\.system\\executor_execution\\7\\.temp\\7\\kt_hyperband\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.MultiObjective object at 0x00000276685B4670>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_unit1: 136\n",
      "dense_unit2: 360\n",
      "dense_unit3: 360\n",
      "learning_rate: 0.01\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 2.615494728088379\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_unit1: 360\n",
      "dense_unit2: 296\n",
      "dense_unit3: 392\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 2.615527629852295\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_unit1: 360\n",
      "dense_unit2: 392\n",
      "dense_unit3: 200\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0002\n",
      "Score: 2.6156678199768066\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_unit1: 360\n",
      "dense_unit2: 392\n",
      "dense_unit3: 200\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 2.6156952381134033\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_unit1: 296\n",
      "dense_unit2: 264\n",
      "dense_unit3: 168\n",
      "learning_rate: 0.01\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 2.615739583969116\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_unit1: 136\n",
      "dense_unit2: 360\n",
      "dense_unit3: 360\n",
      "learning_rate: 0.01\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0001\n",
      "Score: 2.615823268890381\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_unit1: 200\n",
      "dense_unit2: 104\n",
      "dense_unit3: 264\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 2.615872621536255\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_unit1: 200\n",
      "dense_unit2: 104\n",
      "dense_unit3: 104\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 2.615879774093628\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_unit1: 488\n",
      "dense_unit2: 136\n",
      "dense_unit3: 360\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 2.6159846782684326\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dense_unit1: 72\n",
      "dense_unit2: 488\n",
      "dense_unit3: 328\n",
      "learning_rate: 1e-05\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 2.616243839263916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " movieid_xf (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " genres_xf (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " userid_xf (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 2)            0           ['movieid_xf[0][0]',             \n",
      "                                                                  'genres_xf[0][0]']              \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 360)          179552      ['userid_xf[0][0]']              \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 360)          179688      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_2 (TFOpLa  (None, 360)         0           ['sequential_2[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_3 (TFOpLa  (None, 360)         0           ['sequential_3[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 1)            0           ['tf.math.l2_normalize_2[0][0]', \n",
      "                                                                  'tf.math.l2_normalize_3[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 359,240\n",
      "Trainable params: 359,240\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 7.0330 - root_mean_squared_error: 2.6520 - val_loss: 6.8459 - val_root_mean_squared_error: 2.6165\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 6.6937 - root_mean_squared_error: 2.5872 - val_loss: 6.8441 - val_root_mean_squared_error: 2.6161\n",
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\cbf_pipeline\\Trainer\\model\\8\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs\\cbf_pipeline\\Trainer\\model\\8\\Format-Serving\\assets\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000027667B4F100> and <keras.engine.input_layer.InputLayer object at 0x0000027667B973A0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000027667B4F100> and <keras.engine.input_layer.InputLayer object at 0x0000027667B973A0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000027667AA17C0> and <keras.engine.input_layer.InputLayer object at 0x000002760FE0F760>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000027667AA17C0> and <keras.engine.input_layer.InputLayer object at 0x000002760FE0F760>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002766D8240A0> and <keras.engine.input_layer.InputLayer object at 0x000002766D7FAA00>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002766D8240A0> and <keras.engine.input_layer.InputLayer object at 0x000002766D7FAA00>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002766D8699A0> and <keras.engine.input_layer.InputLayer object at 0x0000027667B4CBB0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002766D8699A0> and <keras.engine.input_layer.InputLayer object at 0x0000027667B4CBB0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000276670978E0> and <keras.engine.input_layer.InputLayer object at 0x0000027668555790>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000276670978E0> and <keras.engine.input_layer.InputLayer object at 0x0000027668555790>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000276BEB28130> and <keras.engine.input_layer.InputLayer object at 0x00000276BEB1F7C0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000276BEB28130> and <keras.engine.input_layer.InputLayer object at 0x00000276BEB1F7C0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000276D3A66E20> and <keras.engine.input_layer.InputLayer object at 0x00000276D3A99BB0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000276D3A66E20> and <keras.engine.input_layer.InputLayer object at 0x00000276D3A99BB0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000276EEDBA520> and <keras.engine.input_layer.InputLayer object at 0x00000276EED58910>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000276EEDBA520> and <keras.engine.input_layer.InputLayer object at 0x00000276EED58910>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    }
   ],
   "source": [
    "components = components.init_components(\n",
    "    data_dir=DATA_ROOT,\n",
    "    transform_module=TRANSFORM_MODULE_FILE,\n",
    "    tuner_module=TUNER_MODULE_FILE,\n",
    "    trainer_module=TRAINER_MODULE_FILE,\n",
    "    train_steps=1000,\n",
    "    eval_steps=500,\n",
    "    serving_model_dir=os.path.join(\n",
    "        serving_model_dir, \"cbf_model\"),\n",
    "    epochs=5,\n",
    ")\n",
    "\n",
    "pipeline = pipeline.init_pipeline(\n",
    "    pipeline_root=pipeline_root,\n",
    "    pipeline_name=PIPELINE_NAME,\n",
    "    metadata_path=metadata_path,\n",
    "    components=components,\n",
    ")\n",
    "\n",
    "BeamDagRunner().run(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movies-rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e25223de69fee5703ad0c26aae235f0717de5f7833afcaf5995714c1d7d9212"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
