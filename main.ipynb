{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import tensorflow as tf\n",
                "from modules import components, pipeline\n",
                "from modules.merge_dataset import merge_dataset\n",
                "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'Merge dataset success'"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "merge_dataset(\"data/movies.csv\", \"data/ratings.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "PIPELINE_NAME = \"movie-recommender-pipeline\"\n",
                "\n",
                "# pipeline inputs\n",
                "DATA_ROOT = \"data/merge\"\n",
                "TRANSFORM_MODULE_FILE = \"modules/transform.py\"\n",
                "TUNER_MODULE_FILE = \"modules/tuner.py\"\n",
                "TRAINER_MODULE_FILE = \"modules/trainer.py\"\n",
                "\n",
                "# pipeline outputs\n",
                "OUTPUT_BASE = \"outputs\"\n",
                "\n",
                "serving_model_dir = os.path.join(OUTPUT_BASE, \"serving_model\")\n",
                "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
                "metadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:From c:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
                        "Instructions for updating:\n",
                        "Use ref() instead.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:From c:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
                        "Instructions for updating:\n",
                        "Use ref() instead.\n",
                        "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.\n",
                        "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
                        "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
                        "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
                        "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
                        "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.\n",
                        "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[DatasetKey, DatasetCache] instead.\n",
                        "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[PDone] instead.\n",
                        "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[DatasetKey, DatasetCache] instead.\n",
                        "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[PDone] instead.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Transform\\transform_graph\\85\\.temp_path\\tftransform_tmp\\dd3d2d02df124b64b3e0418d4f64b416\\assets\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Transform\\transform_graph\\85\\.temp_path\\tftransform_tmp\\dd3d2d02df124b64b3e0418d4f64b416\\assets\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Transform\\transform_graph\\85\\.temp_path\\tftransform_tmp\\79f03343028a4863a8917bb05243c857\\assets\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Transform\\transform_graph\\85\\.temp_path\\tftransform_tmp\\79f03343028a4863a8917bb05243c857\\assets\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
                        "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
                        "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "ERROR:absl:ERROR IN run_fn during fit:\n",
                        "in user code:\n",
                        "\n",
                        "    File \"c:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n",
                        "        return step_function(self, iterator)\n",
                        "    File \"c:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n",
                        "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
                        "    File \"c:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n",
                        "        outputs = model.train_step(data)\n",
                        "    File \"c:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n",
                        "        loss = self.compute_loss(inputs, training=True)\n",
                        "    File \"c:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 61, in compute_loss\n",
                        "        raise NotImplementedError(\n",
                        "\n",
                        "    NotImplementedError: Implementers must implement the `compute_loss` method.\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n",
                        "ERROR:absl:ERROR IN _get_serve_tf_examples_fn:\n",
                        "TensorSpec(shape=(None,), dtype=tf.string, name='examples') is not a callable object.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Skipping full serialization of Keras layer <trainer.RecommenderNet object at 0x000002B65C9793A0>, because it is not built.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:Skipping full serialization of Keras layer <trainer.RecommenderNet object at 0x000002B65C9793A0>, because it is not built.\n",
                        "ERROR:absl:ERROR IN run_fn during export:\n",
                        "Model <trainer.RecommenderNet object at 0x000002B65C9793A0> cannot be saved either because the input shape is not available or because the forward pass of the model is not defined.To define a forward pass, please override `Model.call()`. To specify an input shape, either call `build(input_shape)` directly, or call the model on actual data using `Model()`, `Model.fit()`, or `Model.predict()`. If you have a custom training step, please make sure to invoke the forward pass in train step through `Model.__call__`, i.e. `model(inputs)`, as opposed to `model.call()`.\n",
                        "ERROR:absl:Execution 87 failed.\n"
                    ]
                },
                {
                    "ename": "RuntimeError",
                    "evalue": "run_fn failed to generate model. [while running 'Run[Trainer]']",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\common.py:1417\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\common.py:837\u001b[0m, in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker.invoke_process\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\common.py:983\u001b[0m, in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\beam\\beam_dag_runner.py:90\u001b[0m, in \u001b[0;36mPipelineNodeAsDoFn.process\u001b[1;34m(self, element, *signals)\u001b[0m\n\u001b[0;32m     89\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mnode \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is running.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_node_id)\n\u001b[1;32m---> 90\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_node()\n\u001b[0;32m     91\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mnode \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is finished.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_node_id)\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\beam\\beam_dag_runner.py:99\u001b[0m, in \u001b[0;36mPipelineNodeAsDoFn._run_node\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m     partial_run_utils\u001b[39m.\u001b[39msnapshot(mlmd_handle, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline)\n\u001b[1;32m---> 99\u001b[0m launcher\u001b[39m.\u001b[39;49mLauncher(\n\u001b[0;32m    100\u001b[0m     pipeline_node\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipeline_node,\n\u001b[0;32m    101\u001b[0m     mlmd_connection\u001b[39m=\u001b[39;49mmetadata\u001b[39m.\u001b[39;49mMetadata(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mlmd_connection_config),\n\u001b[0;32m    102\u001b[0m     pipeline_info\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipeline_info,\n\u001b[0;32m    103\u001b[0m     pipeline_runtime_spec\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipeline_runtime_spec,\n\u001b[0;32m    104\u001b[0m     executor_spec\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executor_spec,\n\u001b[0;32m    105\u001b[0m     platform_config\u001b[39m=\u001b[39;49mplatform_config,\n\u001b[0;32m    106\u001b[0m     custom_driver_spec\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_custom_driver_spec)\u001b[39m.\u001b[39;49mlaunch()\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\portable\\launcher.py:571\u001b[0m, in \u001b[0;36mLauncher.launch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    570\u001b[0m     executor_watcher\u001b[39m.\u001b[39mstart()\n\u001b[1;32m--> 571\u001b[0m   executor_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_executor(execution_info)\n\u001b[0;32m    572\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\portable\\launcher.py:446\u001b[0m, in \u001b[0;36mLauncher._run_executor\u001b[1;34m(self, execution_info)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 446\u001b[0m   executor_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executor_operator\u001b[39m.\u001b[39;49mrun_executor(execution_info)\n\u001b[0;32m    447\u001b[0m   code \u001b[39m=\u001b[39m executor_output\u001b[39m.\u001b[39mexecution_result\u001b[39m.\u001b[39mcode\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\portable\\python_executor_operator.py:135\u001b[0m, in \u001b[0;36mPythonExecutorOperator.run_executor\u001b[1;34m(self, execution_info)\u001b[0m\n\u001b[0;32m    134\u001b[0m executor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_cls(context\u001b[39m=\u001b[39mcontext)\n\u001b[1;32m--> 135\u001b[0m \u001b[39mreturn\u001b[39;00m run_with_executor(execution_info, executor)\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\portable\\python_executor_operator.py:58\u001b[0m, in \u001b[0;36mrun_with_executor\u001b[1;34m(execution_info, executor)\u001b[0m\n\u001b[0;32m     57\u001b[0m output_dict \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(execution_info\u001b[39m.\u001b[39moutput_dict)\n\u001b[1;32m---> 58\u001b[0m result \u001b[39m=\u001b[39m executor\u001b[39m.\u001b[39;49mDo(execution_info\u001b[39m.\u001b[39;49minput_dict, output_dict,\n\u001b[0;32m     59\u001b[0m                      execution_info\u001b[39m.\u001b[39;49mexec_properties)\n\u001b[0;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result:\n\u001b[0;32m     61\u001b[0m   \u001b[39m# If result is not returned from the Do function, then try to\u001b[39;00m\n\u001b[0;32m     62\u001b[0m   \u001b[39m# read from the executor_output_uri.\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\components\\trainer\\executor.py:183\u001b[0m, in \u001b[0;36mGenericExecutor.Do\u001b[1;34m(self, input_dict, output_dict, exec_properties)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fileio\u001b[39m.\u001b[39mexists(fn_args\u001b[39m.\u001b[39mserving_model_dir):\n\u001b[1;32m--> 183\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mrun_fn failed to generate model.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    185\u001b[0m absl\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    186\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mTraining complete. Model written to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. ModelRun written to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m    187\u001b[0m     fn_args\u001b[39m.\u001b[39mserving_model_dir, fn_args\u001b[39m.\u001b[39mmodel_run_dir)\n",
                        "\u001b[1;31mRuntimeError\u001b[0m: run_fn failed to generate model.",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m      1\u001b[0m components \u001b[39m=\u001b[39m components\u001b[39m.\u001b[39minit_components(\n\u001b[0;32m      2\u001b[0m     data_dir\u001b[39m=\u001b[39mDATA_ROOT,\n\u001b[0;32m      3\u001b[0m     transform_module\u001b[39m=\u001b[39mTRANSFORM_MODULE_FILE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m pipeline \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39minit_pipeline(\n\u001b[0;32m     13\u001b[0m     pipeline_root\u001b[39m=\u001b[39mpipeline_root,\n\u001b[0;32m     14\u001b[0m     pipeline_name\u001b[39m=\u001b[39mPIPELINE_NAME,\n\u001b[0;32m     15\u001b[0m     metadata_path\u001b[39m=\u001b[39mmetadata_path,\n\u001b[0;32m     16\u001b[0m     components\u001b[39m=\u001b[39mcomponents,\n\u001b[0;32m     17\u001b[0m )\n\u001b[1;32m---> 19\u001b[0m BeamDagRunner()\u001b[39m.\u001b[39;49mrun(pipeline)\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\portable\\tfx_runner.py:124\u001b[0m, in \u001b[0;36mIrBasedRunner.run\u001b[1;34m(self, pipeline, run_options, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m   run_options_pb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_with_ir(pipeline_pb, run_options\u001b[39m=\u001b[39;49mrun_options_pb, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\beam\\beam_dag_runner.py:297\u001b[0m, in \u001b[0;36mBeamDagRunner.run_with_ir\u001b[1;34m(self, pipeline, run_options)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39m# Each signal is an empty PCollection. AsIter ensures a node will\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[39m# be triggered after upstream nodes are finished.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m signal_map[node_id] \u001b[39m=\u001b[39m (\n\u001b[0;32m    285\u001b[0m     root\n\u001b[0;32m    286\u001b[0m     \u001b[39m|\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRun[\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m node_id \u001b[39m>>\u001b[39m beam\u001b[39m.\u001b[39mParDo(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    295\u001b[0m             pipeline\u001b[39m=\u001b[39mpipeline),\n\u001b[0;32m    296\u001b[0m         \u001b[39m*\u001b[39m[beam\u001b[39m.\u001b[39mpvalue\u001b[39m.\u001b[39mAsIter(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m signals_to_wait]))\n\u001b[1;32m--> 297\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mNode \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is scheduled.\u001b[39m\u001b[39m'\u001b[39m, node_id)\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\pipeline.py:597\u001b[0m, in \u001b[0;36mPipeline.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    596\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exc_type:\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m    598\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult\u001b[39m.\u001b[39mwait_until_finish()\n\u001b[0;32m    599\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\pipeline.py:574\u001b[0m, in \u001b[0;36mPipeline.run\u001b[1;34m(self, test_runner_api)\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    573\u001b[0m       shutil\u001b[39m.\u001b[39mrmtree(tmpdir)\n\u001b[1;32m--> 574\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunner\u001b[39m.\u001b[39;49mrun_pipeline(\u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_options)\n\u001b[0;32m    575\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_in_ipython():\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\direct\\direct_runner.py:131\u001b[0m, in \u001b[0;36mSwitchingDirectRunner.run_pipeline\u001b[1;34m(self, pipeline, options)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m   runner \u001b[39m=\u001b[39m BundleBasedDirectRunner()\n\u001b[1;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m runner\u001b[39m.\u001b[39;49mrun_pipeline(pipeline, options)\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\fn_runner.py:199\u001b[0m, in \u001b[0;36mFnApiRunner.run_pipeline\u001b[1;34m(self, pipeline, options)\u001b[0m\n\u001b[0;32m    188\u001b[0m   _LOGGER\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    189\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mIf direct_num_workers is not equal to 1, direct_running_mode \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    190\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mshould be `multi_processing` or `multi_threading` instead of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_workers,\n\u001b[0;32m    194\u001b[0m       running_mode)\n\u001b[0;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profiler_factory \u001b[39m=\u001b[39m Profile\u001b[39m.\u001b[39mfactory_from_options(\n\u001b[0;32m    197\u001b[0m     options\u001b[39m.\u001b[39mview_as(pipeline_options\u001b[39m.\u001b[39mProfilingOptions))\n\u001b[1;32m--> 199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_latest_run_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_via_runner_api(\n\u001b[0;32m    200\u001b[0m     pipeline\u001b[39m.\u001b[39;49mto_runner_api(default_environment\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_environment),\n\u001b[0;32m    201\u001b[0m     options)\n\u001b[0;32m    202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_latest_run_result\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\fn_runner.py:212\u001b[0m, in \u001b[0;36mFnApiRunner.run_via_runner_api\u001b[1;34m(self, pipeline_proto, options)\u001b[0m\n\u001b[0;32m    210\u001b[0m   pipeline_proto \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_default_docker_image(pipeline_proto)\n\u001b[0;32m    211\u001b[0m stage_context, stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_stages(pipeline_proto)\n\u001b[1;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_stages(stage_context, stages)\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\fn_runner.py:442\u001b[0m, in \u001b[0;36mFnApiRunner.run_stages\u001b[1;34m(self, stage_context, stages)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39massert\u001b[39;00m consuming_stage_name \u001b[39m==\u001b[39m bundle_context_manager\u001b[39m.\u001b[39mstage\u001b[39m.\u001b[39mname\n\u001b[0;32m    441\u001b[0m bundle_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 442\u001b[0m bundle_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_bundle(\n\u001b[0;32m    443\u001b[0m     runner_execution_context, bundle_context_manager, bundle_input)\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m consuming_stage_name \u001b[39min\u001b[39;00m monitoring_infos_by_stage:\n\u001b[0;32m    446\u001b[0m   monitoring_infos_by_stage[\n\u001b[0;32m    447\u001b[0m       consuming_stage_name] \u001b[39m=\u001b[39m consolidate_monitoring_infos(\n\u001b[0;32m    448\u001b[0m           itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    449\u001b[0m               bundle_results\u001b[39m.\u001b[39mprocess_bundle\u001b[39m.\u001b[39mmonitoring_infos,\n\u001b[0;32m    450\u001b[0m               monitoring_infos_by_stage[consuming_stage_name]))\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\fn_runner.py:770\u001b[0m, in \u001b[0;36mFnApiRunner._execute_bundle\u001b[1;34m(self, runner_execution_context, bundle_context_manager, bundle_input)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[39m# We create the bundle manager here, as it can be reused for bundles of\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[39m# the same stage, but it may have to be created by-bundle later on.\u001b[39;00m\n\u001b[0;32m    767\u001b[0m bundle_manager \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bundle_manager(bundle_context_manager)\n\u001b[0;32m    769\u001b[0m last_result, deferred_inputs, newly_set_timers, watermark_updates \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 770\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_bundle(\n\u001b[0;32m    771\u001b[0m         runner_execution_context,\n\u001b[0;32m    772\u001b[0m         bundle_context_manager,\n\u001b[0;32m    773\u001b[0m         bundle_input,\n\u001b[0;32m    774\u001b[0m         bundle_context_manager\u001b[39m.\u001b[39;49mstage_data_outputs,\n\u001b[0;32m    775\u001b[0m         bundle_context_manager\u001b[39m.\u001b[39;49mstage_timer_outputs,\n\u001b[0;32m    776\u001b[0m         bundle_manager))\n\u001b[0;32m    778\u001b[0m \u001b[39mfor\u001b[39;00m pc_name, watermark \u001b[39min\u001b[39;00m watermark_updates\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    779\u001b[0m   _BUNDLE_LOGGER\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39mUpdate: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, pc_name, watermark)\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\fn_runner.py:999\u001b[0m, in \u001b[0;36mFnApiRunner._run_bundle\u001b[1;34m(self, runner_execution_context, bundle_context_manager, bundle_input, data_output, expected_timer_output, bundle_manager)\u001b[0m\n\u001b[0;32m    990\u001b[0m input_timers \u001b[39m=\u001b[39m bundle_input\u001b[39m.\u001b[39mtimers\n\u001b[0;32m    991\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_bundle_multiple_times_for_testing(\n\u001b[0;32m    992\u001b[0m     runner_execution_context,\n\u001b[0;32m    993\u001b[0m     bundle_manager,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    996\u001b[0m     input_timers,\n\u001b[0;32m    997\u001b[0m     expected_timer_output)\n\u001b[1;32m--> 999\u001b[0m result, splits \u001b[39m=\u001b[39m bundle_manager\u001b[39m.\u001b[39;49mprocess_bundle(\n\u001b[0;32m   1000\u001b[0m     data_input, data_output, input_timers, expected_timer_output)\n\u001b[0;32m   1001\u001b[0m \u001b[39m# Now we collect all the deferred inputs remaining from bundle execution.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[39m# Deferred inputs can be:\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m \u001b[39m# - timers\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[39m# - SDK-initiated deferred applications of root elements\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[39m# - Runner-initiated deferred applications of root elements\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m deferred_inputs \u001b[39m=\u001b[39m {}  \u001b[39m# type: Dict[str, execution.PartitionableBuffer]\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\fn_runner.py:1309\u001b[0m, in \u001b[0;36mBundleManager.process_bundle\u001b[1;34m(self, inputs, expected_outputs, fired_timers, expected_output_timers, dry_run)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[39m# Actually start the bundle.\u001b[39;00m\n\u001b[0;32m   1303\u001b[0m process_bundle_req \u001b[39m=\u001b[39m beam_fn_api_pb2\u001b[39m.\u001b[39mInstructionRequest(\n\u001b[0;32m   1304\u001b[0m     instruction_id\u001b[39m=\u001b[39mprocess_bundle_id,\n\u001b[0;32m   1305\u001b[0m     process_bundle\u001b[39m=\u001b[39mbeam_fn_api_pb2\u001b[39m.\u001b[39mProcessBundleRequest(\n\u001b[0;32m   1306\u001b[0m         process_bundle_descriptor_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbundle_context_manager\u001b[39m.\u001b[39m\n\u001b[0;32m   1307\u001b[0m         process_bundle_descriptor\u001b[39m.\u001b[39mid,\n\u001b[0;32m   1308\u001b[0m         cache_tokens\u001b[39m=\u001b[39m[\u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_token_generator)]))\n\u001b[1;32m-> 1309\u001b[0m result_future \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_worker_handler\u001b[39m.\u001b[39;49mcontrol_conn\u001b[39m.\u001b[39;49mpush(process_bundle_req)\n\u001b[0;32m   1311\u001b[0m split_results \u001b[39m=\u001b[39m []  \u001b[39m# type: List[beam_fn_api_pb2.ProcessBundleSplitResponse]\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[39mwith\u001b[39;00m ProgressRequester(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_worker_handler,\n\u001b[0;32m   1313\u001b[0m                        process_bundle_id,\n\u001b[0;32m   1314\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_progress_frequency):\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\portability\\fn_api_runner\\worker_handlers.py:380\u001b[0m, in \u001b[0;36mEmbeddedWorkerHandler.push\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    378\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_uid_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    379\u001b[0m   request\u001b[39m.\u001b[39minstruction_id \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcontrol_\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_uid_counter\n\u001b[1;32m--> 380\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mworker\u001b[39m.\u001b[39;49mdo_instruction(request)\n\u001b[0;32m    381\u001b[0m \u001b[39mreturn\u001b[39;00m ControlFuture(request\u001b[39m.\u001b[39minstruction_id, response)\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\worker\\sdk_worker.py:597\u001b[0m, in \u001b[0;36mSdkWorker.do_instruction\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    594\u001b[0m request_type \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mWhichOneof(\u001b[39m'\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    595\u001b[0m \u001b[39mif\u001b[39;00m request_type:\n\u001b[0;32m    596\u001b[0m   \u001b[39m# E.g. if register is set, this will call self.register(request.register))\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, request_type)(\n\u001b[0;32m    598\u001b[0m       \u001b[39mgetattr\u001b[39;49m(request, request_type), request\u001b[39m.\u001b[39;49minstruction_id)\n\u001b[0;32m    599\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    600\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\worker\\sdk_worker.py:635\u001b[0m, in \u001b[0;36mSdkWorker.process_bundle\u001b[1;34m(self, request, instruction_id)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mwith\u001b[39;00m bundle_processor\u001b[39m.\u001b[39mstate_handler\u001b[39m.\u001b[39mprocess_instruction_id(\n\u001b[0;32m    632\u001b[0m     instruction_id, request\u001b[39m.\u001b[39mcache_tokens):\n\u001b[0;32m    633\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaybe_profile(instruction_id):\n\u001b[0;32m    634\u001b[0m     delayed_applications, requests_finalization \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 635\u001b[0m         bundle_processor\u001b[39m.\u001b[39;49mprocess_bundle(instruction_id))\n\u001b[0;32m    636\u001b[0m     monitoring_infos \u001b[39m=\u001b[39m bundle_processor\u001b[39m.\u001b[39mmonitoring_infos()\n\u001b[0;32m    637\u001b[0m     monitoring_infos\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_cache_metrics_fn())\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\worker\\bundle_processor.py:1003\u001b[0m, in \u001b[0;36mBundleProcessor.process_bundle\u001b[1;34m(self, instruction_id)\u001b[0m\n\u001b[0;32m   1000\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mops[element\u001b[39m.\u001b[39mtransform_id]\u001b[39m.\u001b[39mprocess_timer(\n\u001b[0;32m   1001\u001b[0m             element\u001b[39m.\u001b[39mtimer_family_id, timer_data)\n\u001b[0;32m   1002\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(element, beam_fn_api_pb2\u001b[39m.\u001b[39mElements\u001b[39m.\u001b[39mData):\n\u001b[1;32m-> 1003\u001b[0m       input_op_by_transform_id[element\u001b[39m.\u001b[39;49mtransform_id]\u001b[39m.\u001b[39;49mprocess_encoded(\n\u001b[0;32m   1004\u001b[0m           element\u001b[39m.\u001b[39;49mdata)\n\u001b[0;32m   1006\u001b[0m \u001b[39m# Finish all operations.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mvalues():\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\worker\\bundle_processor.py:227\u001b[0m, in \u001b[0;36mDataInputOperation.process_encoded\u001b[1;34m(self, encoded_windowed_values)\u001b[0m\n\u001b[0;32m    224\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    225\u001b[0m decoded_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindowed_coder_impl\u001b[39m.\u001b[39mdecode_from_stream(\n\u001b[0;32m    226\u001b[0m     input_stream, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 227\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(decoded_value)\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\worker\\operations.py:526\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\worker\\operations.py:528\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.Operation.output\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\worker\\operations.py:237\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\worker\\operations.py:240\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\worker\\operations.py:907\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\worker\\operations.py:908\u001b[0m, in \u001b[0;36mapache_beam.runners.worker.operations.DoOperation.process\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\common.py:1419\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\common.py:1507\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner._reraise_augmented\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\common.py:1417\u001b[0m, in \u001b[0;36mapache_beam.runners.common.DoFnRunner.process\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\common.py:837\u001b[0m, in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker.invoke_process\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\apache_beam\\runners\\common.py:983\u001b[0m, in \u001b[0;36mapache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\beam\\beam_dag_runner.py:90\u001b[0m, in \u001b[0;36mPipelineNodeAsDoFn.process\u001b[1;34m(self, element, *signals)\u001b[0m\n\u001b[0;32m     87\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlist\u001b[39m(signal), \u001b[39m'\u001b[39m\u001b[39mSignal PCollection should be empty.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     89\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mnode \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is running.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_node_id)\n\u001b[1;32m---> 90\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_node()\n\u001b[0;32m     91\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mnode \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is finished.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_node_id)\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\beam\\beam_dag_runner.py:99\u001b[0m, in \u001b[0;36mPipelineNodeAsDoFn._run_node\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[39mwith\u001b[39;00m metadata\u001b[39m.\u001b[39mMetadata(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mlmd_connection_config) \u001b[39mas\u001b[39;00m mlmd_handle:\n\u001b[0;32m     98\u001b[0m     partial_run_utils\u001b[39m.\u001b[39msnapshot(mlmd_handle, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline)\n\u001b[1;32m---> 99\u001b[0m launcher\u001b[39m.\u001b[39;49mLauncher(\n\u001b[0;32m    100\u001b[0m     pipeline_node\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipeline_node,\n\u001b[0;32m    101\u001b[0m     mlmd_connection\u001b[39m=\u001b[39;49mmetadata\u001b[39m.\u001b[39;49mMetadata(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mlmd_connection_config),\n\u001b[0;32m    102\u001b[0m     pipeline_info\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipeline_info,\n\u001b[0;32m    103\u001b[0m     pipeline_runtime_spec\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipeline_runtime_spec,\n\u001b[0;32m    104\u001b[0m     executor_spec\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executor_spec,\n\u001b[0;32m    105\u001b[0m     platform_config\u001b[39m=\u001b[39;49mplatform_config,\n\u001b[0;32m    106\u001b[0m     custom_driver_spec\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_custom_driver_spec)\u001b[39m.\u001b[39;49mlaunch()\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\portable\\launcher.py:571\u001b[0m, in \u001b[0;36mLauncher.launch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_operator\u001b[39m.\u001b[39mwith_execution_watcher(\n\u001b[0;32m    569\u001b[0m         executor_watcher\u001b[39m.\u001b[39maddress)\n\u001b[0;32m    570\u001b[0m     executor_watcher\u001b[39m.\u001b[39mstart()\n\u001b[1;32m--> 571\u001b[0m   executor_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_executor(execution_info)\n\u001b[0;32m    572\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    573\u001b[0m   execution_output \u001b[39m=\u001b[39m (\n\u001b[0;32m    574\u001b[0m       e\u001b[39m.\u001b[39mexecutor_output \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, _ExecutionFailedError) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\portable\\launcher.py:446\u001b[0m, in \u001b[0;36mLauncher._run_executor\u001b[1;34m(self, execution_info)\u001b[0m\n\u001b[0;32m    444\u001b[0m outputs_utils\u001b[39m.\u001b[39mmake_output_dirs(execution_info\u001b[39m.\u001b[39moutput_dict)\n\u001b[0;32m    445\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 446\u001b[0m   executor_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executor_operator\u001b[39m.\u001b[39;49mrun_executor(execution_info)\n\u001b[0;32m    447\u001b[0m   code \u001b[39m=\u001b[39m executor_output\u001b[39m.\u001b[39mexecution_result\u001b[39m.\u001b[39mcode\n\u001b[0;32m    448\u001b[0m   \u001b[39mif\u001b[39;00m code \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\portable\\python_executor_operator.py:135\u001b[0m, in \u001b[0;36mPythonExecutorOperator.run_executor\u001b[1;34m(self, execution_info)\u001b[0m\n\u001b[0;32m    125\u001b[0m context \u001b[39m=\u001b[39m base_executor\u001b[39m.\u001b[39mBaseExecutor\u001b[39m.\u001b[39mContext(\n\u001b[0;32m    126\u001b[0m     extra_flags\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextra_flags,\n\u001b[0;32m    127\u001b[0m     tmp_dir\u001b[39m=\u001b[39mexecution_info\u001b[39m.\u001b[39mtmp_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m     pipeline_info\u001b[39m=\u001b[39mexecution_info\u001b[39m.\u001b[39mpipeline_info,\n\u001b[0;32m    133\u001b[0m     pipeline_run_id\u001b[39m=\u001b[39mexecution_info\u001b[39m.\u001b[39mpipeline_run_id)\n\u001b[0;32m    134\u001b[0m executor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_cls(context\u001b[39m=\u001b[39mcontext)\n\u001b[1;32m--> 135\u001b[0m \u001b[39mreturn\u001b[39;00m run_with_executor(execution_info, executor)\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\orchestration\\portable\\python_executor_operator.py:58\u001b[0m, in \u001b[0;36mrun_with_executor\u001b[1;34m(execution_info, executor)\u001b[0m\n\u001b[0;32m     55\u001b[0m       artifact\u001b[39m.\u001b[39mread()\n\u001b[0;32m     57\u001b[0m output_dict \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(execution_info\u001b[39m.\u001b[39moutput_dict)\n\u001b[1;32m---> 58\u001b[0m result \u001b[39m=\u001b[39m executor\u001b[39m.\u001b[39;49mDo(execution_info\u001b[39m.\u001b[39;49minput_dict, output_dict,\n\u001b[0;32m     59\u001b[0m                      execution_info\u001b[39m.\u001b[39;49mexec_properties)\n\u001b[0;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result:\n\u001b[0;32m     61\u001b[0m   \u001b[39m# If result is not returned from the Do function, then try to\u001b[39;00m\n\u001b[0;32m     62\u001b[0m   \u001b[39m# read from the executor_output_uri.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m fileio\u001b[39m.\u001b[39mexists(execution_info\u001b[39m.\u001b[39mexecution_output_uri):\n",
                        "File \u001b[1;32mc:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tfx\\components\\trainer\\executor.py:183\u001b[0m, in \u001b[0;36mGenericExecutor.Do\u001b[1;34m(self, input_dict, output_dict, exec_properties)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39m# Note: If trained with multi-node distribution workers, it is the user\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[39m# module's responsibility to export the model only once.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fileio\u001b[39m.\u001b[39mexists(fn_args\u001b[39m.\u001b[39mserving_model_dir):\n\u001b[1;32m--> 183\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mrun_fn failed to generate model.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    185\u001b[0m absl\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    186\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mTraining complete. Model written to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. ModelRun written to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m    187\u001b[0m     fn_args\u001b[39m.\u001b[39mserving_model_dir, fn_args\u001b[39m.\u001b[39mmodel_run_dir)\n",
                        "\u001b[1;31mRuntimeError\u001b[0m: run_fn failed to generate model. [while running 'Run[Trainer]']"
                    ]
                }
            ],
            "source": [
                "components = components.init_components(\n",
                "    data_dir=DATA_ROOT,\n",
                "    transform_module=TRANSFORM_MODULE_FILE,\n",
                "    tuner_module=TUNER_MODULE_FILE,\n",
                "    trainer_module=TRAINER_MODULE_FILE,\n",
                "    train_steps=500,\n",
                "    eval_steps=100,\n",
                "    serving_model_dir=serving_model_dir,\n",
                "    epochs=5,\n",
                ")\n",
                "\n",
                "pipeline = pipeline.init_pipeline(\n",
                "    pipeline_root=pipeline_root,\n",
                "    pipeline_name=PIPELINE_NAME,\n",
                "    metadata_path=metadata_path,\n",
                "    components=components,\n",
                ")\n",
                "\n",
                "BeamDagRunner().run(pipeline)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.0 ('movies-rec')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "c8bee75823cf711cdc108f50355468f4211d8df5db436ac62360d8c22fcdec6c"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
