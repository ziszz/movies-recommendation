{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from modules.merge_dataset import merge_dataset\n",
                "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
                "from modules import pipeline, components"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'Merge dataset success'"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "merge_dataset(\"data/movie.csv\", \"data/rating.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "PIPELINE_NAME = \"movie-recommender-pipeline\"\n",
                "\n",
                "# pipeline inputs\n",
                "DATA_ROOT = \"data/merge\"\n",
                "TRANSFORM_MODULE_FILE = \"modules/transform.py\"\n",
                "TUNER_MODULE_FILE = \"modules/tuner.py\"\n",
                "TRAINER_MODULE_FILE = \"modules/trainer.py\"\n",
                "\n",
                "# pipeline outputs\n",
                "OUTPUT_BASE = \"outputs\"\n",
                "\n",
                "serving_model_dir = os.path.join(OUTPUT_BASE, \"serving_model\")\n",
                "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
                "metadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:From c:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
                        "Instructions for updating:\n",
                        "Use ref() instead.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:From c:\\Users\\Zis\\anaconda3\\envs\\movies-rec\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
                        "Instructions for updating:\n",
                        "Use ref() instead.\n",
                        "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.\n",
                        "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
                        "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
                        "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
                        "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
                        "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.\n",
                        "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[DatasetKey, DatasetCache] instead.\n",
                        "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[PDone] instead.\n",
                        "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[DatasetKey, DatasetCache] instead.\n",
                        "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[PDone] instead.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Transform\\transform_graph\\4\\.temp_path\\tftransform_tmp\\85ab39dee323461bbdfd03496105c37c\\assets\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Transform\\transform_graph\\4\\.temp_path\\tftransform_tmp\\85ab39dee323461bbdfd03496105c37c\\assets\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Transform\\transform_graph\\4\\.temp_path\\tftransform_tmp\\dc063949b37a40b291aca766d36ea75c\\assets\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Transform\\transform_graph\\4\\.temp_path\\tftransform_tmp\\dc063949b37a40b291aca766d36ea75c\\assets\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
                        "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
                        "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/5\n",
                        "5000/5000 [==============================] - ETA: 0s - root_mean_squared_error: 275.2292 - loss: 75751.1123 - regularization_loss: 0.1966 - total_loss: 75751.3084\n",
                        "Epoch 1: val_root_mean_squared_error improved from inf to 17718.69336, saving model to outputs\\movie-recommender-pipeline\\Trainer\\model\\6\\Format-Serving\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:absl:Function `_wrapped_model` contains input name(s) movieId_xf, userId_xf with unsupported characters which will be renamed to movieid_xf, userid_xf in the SavedModel.\n",
                        "WARNING:absl:Found untraced functions such as ranking_layer_call_fn, ranking_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Trainer\\model\\6\\Format-Serving\\assets\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Trainer\\model\\6\\Format-Serving\\assets\n",
                        "ERROR:absl:ERROR IN run_fn during fit:\n",
                        "Unable to serialize b'3907' to JSON. Unrecognized type <class 'bytes'>.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n",
                        "WARNING:absl:Found untraced functions such as ranking_layer_call_fn, ranking_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Trainer\\model\\6\\Format-Serving\\assets\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Trainer\\model\\6\\Format-Serving\\assets\n",
                        "ERROR:absl:ERROR IN run_fn during export:\n",
                        "Unable to serialize b'3907' to JSON. Unrecognized type <class 'bytes'>.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:Pusher is going to push the model without validation. Consider using Evaluator or InfraValidator in your pipeline.\n"
                    ]
                }
            ],
            "source": [
                "components_args = {\n",
                "    \"data_dir\": DATA_ROOT,\n",
                "    \"transform_module\": TRANSFORM_MODULE_FILE,\n",
                "    \"tuner_module\": TUNER_MODULE_FILE,\n",
                "    \"trainer_module\": TRAINER_MODULE_FILE,\n",
                "    \"train_steps\": 5000,\n",
                "    \"eval_steps\": 2000,\n",
                "    \"serving_model_dir\": serving_model_dir,\n",
                "    \"epochs\": 5,\n",
                "}\n",
                "\n",
                "components = components.init_components(components_args)\n",
                "\n",
                "pipeline = pipeline.init_pipeline(\n",
                "    pipeline_root,\n",
                "    PIPELINE_NAME,\n",
                "    metadata_path,\n",
                "    components,\n",
                ")\n",
                "\n",
                "BeamDagRunner().run(pipeline)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.0 ('movies-rec')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "c8bee75823cf711cdc108f50355468f4211d8df5db436ac62360d8c22fcdec6c"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
