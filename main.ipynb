{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from modules.merge_dataset import merge_dataset\n",
                "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
                "from modules import pipeline, components"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'Merge dataset success'"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "merge_dataset(\"data/movie.csv\", \"data/rating.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "PIPELINE_NAME = \"movie-recommender-pipeline\"\n",
                "\n",
                "# pipeline inputs\n",
                "DATA_ROOT = \"data/merge\"\n",
                "TRANSFORM_MODULE_FILE = \"modules/transform.py\"\n",
                "TUNER_MODULE_FILE = \"modules/tuner.py\"\n",
                "TRAINER_MODULE_FILE = \"modules/trainer.py\"\n",
                "\n",
                "# pipeline outputs\n",
                "OUTPUT_BASE = \"outputs\"\n",
                "\n",
                "serving_model_dir = os.path.join(OUTPUT_BASE, \"serving_model\")\n",
                "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
                "metadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ContextQuery.property_predicate is not supported.\n",
                        "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
                        "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.\n",
                        "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
                        "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
                        "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
                        "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
                        "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType], int] instead.\n",
                        "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[DatasetKey, DatasetCache] instead.\n",
                        "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[PDone] instead.\n",
                        "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[DatasetKey, DatasetCache] instead.\n",
                        "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[PDone] instead.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Transform\\transform_graph\\35\\.temp_path\\tftransform_tmp\\a65e158f57444a279e9f925d6da1fa9f\\assets\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Transform\\transform_graph\\35\\.temp_path\\tftransform_tmp\\a65e158f57444a279e9f925d6da1fa9f\\assets\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Transform\\transform_graph\\35\\.temp_path\\tftransform_tmp\\333a7e18da0848b3a1667529f0cd13e6\\assets\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Assets written to: outputs\\movie-recommender-pipeline\\Transform\\transform_graph\\35\\.temp_path\\tftransform_tmp\\333a7e18da0848b3a1667529f0cd13e6\\assets\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:struct2tensor is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:tensorflow_text is not available.\n"
                    ]
                }
            ],
            "source": [
                "components_args = {\n",
                "    \"data_dir\": DATA_ROOT,\n",
                "    \"transform_module\": TRANSFORM_MODULE_FILE,\n",
                "    \"tuner_module\": TUNER_MODULE_FILE,\n",
                "    \"trainer_module\": TRAINER_MODULE_FILE,\n",
                "    \"train_steps\": 1000,\n",
                "    \"eval_steps\": 400,\n",
                "    \"serving_model_dir\": serving_model_dir,\n",
                "    \"epochs\": 5,\n",
                "}\n",
                "\n",
                "components = components.init_components(components_args)\n",
                "\n",
                "pipeline = pipeline.init_pipeline(\n",
                "    pipeline_root,\n",
                "    PIPELINE_NAME,\n",
                "    metadata_path,\n",
                "    components,\n",
                ")\n",
                "\n",
                "BeamDagRunner().run(pipeline)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.0 ('movies-rec')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "c8bee75823cf711cdc108f50355468f4211d8df5db436ac62360d8c22fcdec6c"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
